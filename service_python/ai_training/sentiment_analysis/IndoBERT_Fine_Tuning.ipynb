{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca946807",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install -U transformers accelerate datasets scikit-learn pandas matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b2fa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.code\\python_service\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4513491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21414940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              clean_text review_class  label\n",
      "3111   pertama kali make up lipstick pertama aku warn...     positive      2\n",
      "18679  yes this is my all time favorite hair oil boto...     positive      2\n",
      "17472  sebenernya aku cuma pernah beberapa kali nyoba...     negative      0\n",
      "21451  tarik sama produk liat tutorial stephanie rose...     positive      2\n",
      "20800  aku bilang msh mula bgt dlm dunia permake upan...     positive      2\n",
      "                                             clean_text review_class  label\n",
      "1782  inget banget dulu pas smp dove pernah punya fa...     negative      0\n",
      "3917  aplikasiinnya enak banget busa dgn desain kaya...     positive      2\n",
      "221   formula ringan cukup bagus buat nahan minyak g...     positive      2\n",
      "2135  semua varian pixy stick deodorant entah cuma y...     positive      2\n",
      "5224  sebenernya cinta banget sama semua varian tone...     positive      2\n"
     ]
    }
   ],
   "source": [
    "# === 1. Load dan Persiapan Dataset ===\n",
    "\n",
    "# Load data\n",
    "path_train = './dataset/cleaned_train.csv'\n",
    "path_test = './dataset/cleaned_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(path_train).sample(n=24000, random_state=42)\n",
    "test_df = pd.read_csv(path_test).sample(n=6000, random_state=42)\n",
    "\n",
    "# Map ke label numerik\n",
    "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "train_df['label'] = train_df['review_class'].map(label_map)\n",
    "test_df['label'] = test_df['review_class'].map(label_map)\n",
    "\n",
    "# Print contoh\n",
    "print(train_df[['clean_text', 'review_class', 'label']].head())\n",
    "print(test_df[['clean_text', 'review_class', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76d0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Konversi ke Dataset HuggingFace ===\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['clean_text', 'label']].rename(columns={\"clean_text\": \"text\"}))\n",
    "test_dataset = Dataset.from_pandas(test_df[['clean_text', 'label']].rename(columns={\"clean_text\": \"text\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3976c0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24000/24000 [00:01<00:00, 21839.05 examples/s]\n",
      "Map: 100%|██████████| 6000/6000 [00:00<00:00, 24360.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# === 3. Tokenisasi ===\n",
    "\n",
    "checkpoint = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "train_tokenized = train_dataset.map(tokenize_fn, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6df5760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# === 4. Load Model dan Setup Trainer ===\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36b38ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_34720\\3029752033.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# === 5. Fungsi Evaluasi ===\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1_macro\": f1_score(labels, predictions, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595dafd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 1:32:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>0.538053</td>\n",
       "      <td>0.776500</td>\n",
       "      <td>0.608709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.550259</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.619363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.645167</td>\n",
       "      <td>0.776167</td>\n",
       "      <td>0.633973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.765956</td>\n",
       "      <td>0.767667</td>\n",
       "      <td>0.623110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>1.020073</td>\n",
       "      <td>0.760167</td>\n",
       "      <td>0.620688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5380529165267944,\n",
       " 'eval_accuracy': 0.7765,\n",
       " 'eval_f1_macro': 0.6087092572926717,\n",
       " 'eval_runtime': 154.6199,\n",
       " 'eval_samples_per_second': 38.805,\n",
       " 'eval_steps_per_second': 2.425,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 6. Training dan Evaluasi ===\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c6ed34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7765\n",
      "F1-score: 0.7568965713191518\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.52      0.57       697\n",
      "     neutral       0.46      0.31      0.37      1092\n",
      "    positive       0.84      0.94      0.89      4211\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.65      0.59      0.61      6000\n",
      "weighted avg       0.75      0.78      0.76      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 7. Evaluasi Lengkap dengan Label String ===\n",
    "\n",
    "predictions = trainer.predict(test_tokenized)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "predicted_classes = [inv_label_map[i] for i in predicted_labels]\n",
    "true_classes = [inv_label_map[i] for i in true_labels]\n",
    "\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=[\"negative\", \"neutral\", \"positive\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "538e6c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/indobert_sentiment_model\\\\tokenizer_config.json',\n",
       " './model/indobert_sentiment_model\\\\special_tokens_map.json',\n",
       " './model/indobert_sentiment_model\\\\vocab.txt',\n",
       " './model/indobert_sentiment_model\\\\added_tokens.json',\n",
       " './model/indobert_sentiment_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 8. Simpan Model ===\n",
    "\n",
    "save_path = \"./model/indobert_sentiment_model\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "174fb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "load_path = \".\\model\\indobert_sentiment_model\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(load_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a3ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks: produk jelek dan bodoh\n",
      "Label: negative\n",
      "Confidence: 0.70\n",
      "\n",
      "Teks: Saya sangat senang dengan produk ini!\n",
      "Label: positive\n",
      "Confidence: 0.86\n",
      "\n",
      "Teks: Aku suka produk desainnya, tapi ini jelek kualitasnya\n",
      "Label: neutral\n",
      "Confidence: 0.44\n",
      "\n",
      "Teks: Produk ini luar biasa, saya akan membelinya lagi!\n",
      "Label: positive\n",
      "Confidence: 0.66\n",
      "\n",
      "Teks: Pengiriman sangat cepat dan sesuai harapan.\n",
      "Label: positive\n",
      "Confidence: 0.82\n",
      "\n",
      "Teks: Pelayanan pelanggan sangat membantu dan ramah.\n",
      "Label: positive\n",
      "Confidence: 0.89\n",
      "\n",
      "Teks: Saya puas dengan kualitas dan harganya.\n",
      "Label: positive\n",
      "Confidence: 0.71\n",
      "\n",
      "Teks: Desainnya elegan dan sangat nyaman dipakai.\n",
      "Label: positive\n",
      "Confidence: 0.81\n",
      "\n",
      "Teks: Pelayanannya mengecewakan\n",
      "Label: negative\n",
      "Confidence: 0.69\n",
      "\n",
      "Teks: banyak fitur bermasalah dan menghambat\n",
      "Label: negative\n",
      "Confidence: 0.44\n",
      "\n",
      "Teks: Barang datang rusak dan tidak sesuai deskripsi.\n",
      "Label: negative\n",
      "Confidence: 0.73\n",
      "\n",
      "Teks: Sangat kecewa, tidak akan beli lagi di sini.\n",
      "Label: negative\n",
      "Confidence: 0.74\n",
      "\n",
      "Teks: Aplikasi sering crash dan membuat frustasi.\n",
      "Label: negative\n",
      "Confidence: 0.58\n",
      "\n",
      "Teks: Kualitasnya buruk, terasa murahan.\n",
      "Label: negative\n",
      "Confidence: 0.49\n",
      "\n",
      "Teks: Pengalaman belanja yang sangat buruk.\n",
      "Label: negative\n",
      "Confidence: 0.65\n",
      "\n",
      "Teks: Produk sesuai deskripsi.\n",
      "Label: positive\n",
      "Confidence: 0.45\n",
      "\n",
      "Teks: Masih perlu dicoba beberapa hari ke depan.\n",
      "Label: neutral\n",
      "Confidence: 0.41\n",
      "\n",
      "Teks: Barang diterima. Belum diuji.\n",
      "Label: neutral\n",
      "Confidence: 0.34\n",
      "\n",
      "Teks: Warnanya beda sedikit dari foto.\n",
      "Label: neutral\n",
      "Confidence: 0.42\n",
      "\n",
      "Teks: Tidak ada masalah berarti sejauh ini.\n",
      "Label: neutral\n",
      "Confidence: 0.44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "predictor = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "texts = [\n",
    "    \"produk jelek dan bodoh\",\n",
    "    \"Saya sangat senang dengan produk ini!\",\n",
    "    \"Aku suka produk desainnya, tapi ini jelek kualitasnya\",\n",
    "    \"Produk ini luar biasa, saya akan membelinya lagi!\",\n",
    "    \"Pengiriman sangat cepat dan sesuai harapan.\",\n",
    "    \"Pelayanan pelanggan sangat membantu dan ramah.\",\n",
    "    \"Saya puas dengan kualitas dan harganya.\",\n",
    "    \"Desainnya elegan dan sangat nyaman dipakai.\",\n",
    "\n",
    "    \"Pelayanannya mengecewakan\",\n",
    "    \"banyak fitur bermasalah dan menghambat\",\n",
    "    \"Barang datang rusak dan tidak sesuai deskripsi.\",\n",
    "    \"Sangat kecewa, tidak akan beli lagi di sini.\",\n",
    "    \"Aplikasi sering crash dan membuat frustasi.\",\n",
    "    \"Kualitasnya buruk, terasa murahan.\",\n",
    "    \"Pengalaman belanja yang sangat buruk.\",\n",
    "\n",
    "    \"Produk sesuai deskripsi.\",\n",
    "    \"Masih perlu dicoba beberapa hari ke depan.\",\n",
    "    \"Barang diterima. Belum diuji.\",\n",
    "    \"Warnanya beda sedikit dari foto.\",\n",
    "    \"Tidak ada masalah berarti sejauh ini.\"\n",
    "]\n",
    "\n",
    "results = predictor(texts)\n",
    "\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Teks: {text}\")\n",
    "    print(f\"Label: {result['label']}\")\n",
    "    print(f\"Confidence: {result['score']:.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
